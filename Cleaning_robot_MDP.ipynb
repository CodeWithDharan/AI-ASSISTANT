{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/kcmOhwzBTdNaq1/qNTUk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeWithDharan/AI-ASSISTANT/blob/main/Cleaning_robot_MDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dnxgq0FhAC6",
        "outputId": "bcfabdd3-e529-4703-de28-0e3d1fbb0050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 1\n",
            "iteration: 2\n",
            "iteration: 3\n",
            "iteration: 4\n",
            "iteration: 5\n",
            "iteration: 6\n",
            "iteration: 7\n",
            "iteration: 8\n",
            "iteration: 9\n",
            "iteration: 10\n",
            "iteration: 11\n",
            "iteration: 12\n",
            "iteration: 13\n",
            "iteration: 14\n",
            "iteration: 15\n",
            "Q matrix (optimal):\n",
            "[[1.99993896 0.49996948]\n",
            " [0.99996948 0.62469578]\n",
            " [0.49998474 1.24969578]\n",
            " [0.62484789 2.49969578]\n",
            " [1.24984789 4.99969578]\n",
            " [2.49984789 9.99969578]]\n",
            "Q(optimal):\n",
            "[0 0 1 1 1 1]\n",
            "Optimal Policy:\n",
            "*\n",
            "['Terminal', -1, 1, 1, 1, 'Terminal']\n",
            "*\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def deterministic_robot_cleaning_v1():\n",
        "    # Initialization\n",
        "    states = [0, 1, 2, 3, 4, 5]                # Set of states\n",
        "    actions = [-1, 1]                         # Set of actions\n",
        "    Q = np.zeros((len(states), len(actions)))  # Initial Q can be chosen arbitrarily\n",
        "    Qold = np.copy(Q)                         # Save a backup to compare later\n",
        "    L = 15                                   # Number of iterations\n",
        "    gamma = 0.5                              # Discounting factor\n",
        "    epsilon = 0.001                          # Final error to stop the algorithm\n",
        "\n",
        "    # Deterministic Q-iteration algorithm\n",
        "    for l in range(1, L + 1):\n",
        "        print(f'iteration: {l}')\n",
        "        for ii in range(len(states)):\n",
        "            for jj in range(len(actions)):\n",
        "                next_state = model(states[ii], actions[jj])\n",
        "                Q[ii, jj] = reward(states[ii], actions[jj]) + gamma * np.max(Q[next_state, :])\n",
        "\n",
        "        if np.abs(np.sum(Q - Qold)) < epsilon:\n",
        "            print('Epsilon criteria satisfied!')\n",
        "            break\n",
        "        else:\n",
        "            Qold = np.copy(Q)\n",
        "\n",
        "    # Show the final Q matrix\n",
        "    print('Q matrix (optimal):')\n",
        "    print(Q)\n",
        "\n",
        "    C = np.argmax(Q, axis=1)                   # Finding the max values\n",
        "    print('Q(optimal):')\n",
        "    print(C)\n",
        "    print('Optimal Policy:')\n",
        "    print('*')\n",
        "    print([actions[C[s]] if s not in [0, 5] else 'Terminal' for s in range(len(states))])\n",
        "    print('*')\n",
        "\n",
        "# This function is the transition model of the robot\n",
        "# The inputs are: the current state, and the chosen action\n",
        "# The output is the next state\n",
        "def model(x, u):\n",
        "    next_state = x + u\n",
        "    if next_state < 0:\n",
        "        return 0\n",
        "    elif next_state > 5:\n",
        "        return 5\n",
        "    return next_state\n",
        "\n",
        "# This function is the reward function for the task\n",
        "# The inputs are: the current state, and the chosen action\n",
        "# The output is the expected reward\n",
        "def reward(x, u):\n",
        "    if x == 5 and u == 1:\n",
        "        return 5\n",
        "    elif x == 0 and u == -1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Call the main function\n",
        "deterministic_robot_cleaning_v1()"
      ]
    }
  ]
}